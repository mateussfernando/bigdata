# ETL de Universidades - Big Data

Um projeto de **Extract, Transform, Load (ETL)** que extrai dados de universidades de diferentes paÃ­ses da API HipoLabs e carrega os dados em bancos de dados SQLite e MongoDB.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa um pipeline ETL automatizado que:

- **Extrai** dados de universidades de uma API pÃºblica (`universities.hipolabs.com`)
- **Carrega** os dados em dois tipos de banco de dados:
  - **SQLite**: para armazenamento local estruturado
  - **MongoDB Atlas**: para armazenamento em nuvem (NoSQL)
- **Orquestra** o fluxo com **Prefect** para execuÃ§Ã£o agendada diÃ¡ria

## ğŸš€ Funcionalidades

- âœ… ExtraÃ§Ã£o de dados de universidades por paÃ­s
- âœ… Carregamento em SQLite local
- âœ… Carregamento em MongoDB Atlas
- âœ… Agendamento automÃ¡tico com Prefect (executado diariamente Ã s 8h UTC)
- âœ… Tratamento de erros com retry automÃ¡tico
- âœ… Logging detalhado de operaÃ§Ãµes

## ğŸ“ Estrutura do Projeto

```
bigdata/
â”œâ”€â”€ main.py                      # Script principal para execuÃ§Ã£o manual
â”œâ”€â”€ orchestrate_prefect.py       # OrquestraÃ§Ã£o com Prefect (agendamento)
â”œâ”€â”€ teste.py                     # Scripts de teste
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â”œâ”€â”€ README.md                    # Este arquivo
â””â”€â”€ src/
    â”œâ”€â”€ extract.py              # Classe de extraÃ§Ã£o de dados
    â””â”€â”€ load.py                 # Classe de carregamento (SQLite e MongoDB)
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **requests**: Para requisiÃ§Ãµes HTTP Ã  API
- **SQLite**: Banco de dados local
- **PyMongo**: Driver para MongoDB
- **Prefect**: OrquestraÃ§Ã£o e agendamento de workflows
- **python-dotenv**: Gerenciamento de variÃ¡veis de ambiente
- **pandas**: ManipulaÃ§Ã£o de dados
- **black**: FormataÃ§Ã£o de cÃ³digo

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/mateussfernando/bigdata.git
cd bigdata
```

### 2. Criar ambiente virtual (recomendado)

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# ou
source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar variÃ¡veis de ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
MONGO_URI=mongodb+srv://<usuario>:<senha>@<cluster>.mongodb.net/?retryWrites=true&w=majority
```

## ğŸ’» Uso

### ExecuÃ§Ã£o Manual

Para executar o ETL uma Ãºnica vez:

```bash
python main.py
```

### ExecuÃ§Ã£o com OrquestraÃ§Ã£o Prefect

Para ativar o agendamento automÃ¡tico (execuÃ§Ã£o diÃ¡ria Ã s 8h UTC):

```bash
python orchestrate_prefect.py
```

Isso iniciarÃ¡ a **Prefect Server** e agendarÃ¡ o fluxo para executar automaticamente todos os dias.

### Monitoramento

Acesse a interface do Prefect em `http://localhost:4200` para monitorar as execuÃ§Ãµes do fluxo.

## ğŸ“Š Dados ExtraÃ­dos

O projeto extrai as seguintes informaÃ§Ãµes sobre universidades:

| Campo            | DescriÃ§Ã£o                   |
| ---------------- | --------------------------- |
| `name`           | Nome da universidade        |
| `country`        | PaÃ­s da universidade        |
| `state-province` | Estado/ProvÃ­ncia            |
| `web_pages`      | PÃ¡ginas web da universidade |
| `domains`        | DomÃ­nios da universidade    |

## ğŸ“ Exemplos

### Extract

```python
from src.extract import Extract

extractor = Extract()
universities = extractor.extract_data("Brazil")
print(f"ExtraÃ­das {len(universities)} universidades do Brasil")
```

### Load - SQLite

```python
from src.load import Load

loader = Load()
loader.load_data_sqlite(universities, "tabela_brazil")
```

### Load - MongoDB

```python
from src.load import Load

loader = Load()
loader.load_data_atlas(universities, "universidades", "universidades_brazil")
```

## ğŸ”„ Fluxo ETL com Prefect

O arquivo `orchestrate_prefect.py` define um fluxo Prefect que:

1. **Extrai** dados de universidades do Brasil
2. **Carrega** os dados no MongoDB Atlas
3. **Executa** automaticamente todos os dias Ã s 8h (UTC)

```python
@flow(name="ETL Universities Prefect", log_prints=True)
def etl_universities_flow(country: str = "Brazil"):
    data = extract(country)
    load_data(data, "universidades", "universidades_brazil")
```

**ConfiguraÃ§Ã£o de Agendamento:**

- **Cron**: `0 8 * * *` (todos os dias Ã s 8h UTC)
- **Tags**: `["etl", "universities"]`

## ğŸ› Troubleshooting

### Erro de conexÃ£o com MongoDB

- Verifique se a `MONGO_URI` estÃ¡ correta no arquivo `.env`
- Verifique se seu IP estÃ¡ permitido no MongoDB Atlas
- Verifique a conectividade de rede

### Erro de requisiÃ§Ã£o Ã  API

- Verifique a disponibilidade da API: `http://universities.hipolabs.com`
- Verifique a conectividade de rede
- O retry automÃ¡tico tentarÃ¡ atÃ© 3 vezes com aguardo de 10 segundos

### Prefect nÃ£o estÃ¡ agendando

- Verifique se o Prefect Server estÃ¡ rodando em background
- Acesse `http://localhost:4200` para confirmar
- Verifique os logs do Prefect para mais detalhes

## ğŸ“š API Utilizada

**URL**: `http://universities.hipolabs.com/search?country={country}`

**Exemplo de Resposta**:

```json
[
  {
    "name": "University of SÃ£o Paulo",
    "country": "Brazil",
    "state-province": "SÃ£o Paulo",
    "web_pages": ["http://www.usp.br/"],
    "domains": ["usp.br"]
  }
]
```

## ğŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto.

## ğŸ‘¨â€ğŸ’» Autor

**Mateus Fernando**

---
